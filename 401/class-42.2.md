# Ethics

## Ethics in the workplace

### How does this article relate to ethics in technology. Do you agree or disagree with these articles? What stuck out to you specifically from each article?

The article I chose to read was the [Google Backtracks, Says Its AI Will Not Be Used for Weapons 
or Surveillance](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327) article. 

The article discusses Google's commitment to not using artificial intelligence (AI) for weapons or surveillance following employee protests regarding their involvement in Project Maven. As a student in a coding bootcamp learning about technology, this article highlights the ethical considerations that arise when developing and utilizing AI.

The use of AI in military applications raises concerns about the potential for autonomous weapons and mass surveillance, which could have significant societal impacts. Google's decision to create AI principles and guidelines is a response to employee pressure and aims to ensure that AI is used in socially beneficial ways and avoids overall harm. The article emphasizes the importance of considering ethical implications and adhering to international norms and human rights laws when developing AI systems.

What stood out to me in this article is the mixed reactions among Google employees regarding the AI principles. Some employees expressed skepticism, questioning whether the principles would prevent future government contracts similar to Maven. Additionally, concerns were raised about the qualification of following internationally accepted norms and the need for more transparency and collaboration with organizations like the United Nations to reject autonomous weapons.

Overall, this article underscores the ongoing discussions surrounding the responsible development and use of AI, the impact of technology on society, and the ethical considerations that arise when implementing AI in sensitive domains such as defense and surveillance. It highlights the need for companies and individuals to actively engage in ethical decision-making processes when working with emerging technologies like AI.

> Reference
> 
> [Google Backtracks, Says Its AI Will Not Be Used for Weapons or Surveillance](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)
> 

## Ethics in Technology

### How does this article relate to ethics in technology. Do you agree or disagree with these articles? What stuck out to you specifically from each article?

The article I read was [The ethical dilemmas of self-driving cars](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)

This article raises ethical questions surrounding the behavior of autonomous vehicles in unpredictable situations. As self-driving technology becomes more prevalent, it becomes crucial to determine who the vehicle should prioritize and potentially harm in unavoidable accidents. This dilemma highlights the need for guidelines and standards to address these ethical concerns. Germany has already proposed rules stating that self-driving cars should prioritize minimizing human deaths and avoid discrimination based on age or gender. However, studies show that people tend to prioritize their own safety when they are in control of the situation, which creates a double standard when it comes to how we judge human drivers versus autonomous machines.

I agree with the article that the ethical considerations surrounding self-driving cars are complex and require careful deliberation. It is essential to establish guidelines that prioritize human lives and ensure fairness. Additionally, the article points out that the introduction of self-driving cars will bring new forms of control and choices for passengers, which may eventually lead to greater acceptance and adaptation. 

What struck me most about this article is the notion of the double standard between human drivers and autonomous machines, where we are more forgiving of human errors due to human frailties, but expect flawless decision-making from machines. It raises interesting questions about how we perceive and hold machines accountable for their actions, especially when it comes to ethical decision-making.

> References
> 
> [The ethical dilemmas of self-driving cars](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)